from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, List, Optional

from openai import OpenAI

from .prompts import (
    COMPATIBILITY_INSTRUCTIONS,
    COMPATIBILITY_SYSTEM,
    DIALOGUE_RULES_TEMPLATE,
    GENDER_FEMALE_INSTRUCTION,
    GENDER_MALE_INSTRUCTION,
    IMITATION_RULES,
    IMITATION_SYSTEM,
    REQUESTER_OTHER_INSTRUCTION,
    REQUESTER_SELF_INSTRUCTION,
    ROAST_INSTRUCTIONS,
    ROAST_SYSTEM,
    STORY_LONG_INSTRUCTIONS,
    STORY_SHORT_INSTRUCTIONS,
    STORY_SYSTEM,
)


@dataclass(slots=True)
class StyleSample:
    text: str


@dataclass(slots=True)
class ContextMessage:
    speaker: str
    text: str


@dataclass(slots=True)
class ParticipantProfile:
    name: str
    samples: List[str]


@dataclass(slots=True)
class RequesterProfile:
    name: str
    samples: List[str]
    is_same_person: bool


@dataclass(slots=True)
class DialogueParticipant:
    username: str
    name: str
    samples: List[StyleSample]
    style_summary: Optional[str]
    persona_card: Optional[str]
    relationship_hint: Optional[str]


@dataclass(slots=True)
class StoryCharacter:
    """Character data for story generation."""
    name: str
    username: str
    samples: List[StyleSample]
    style_summary: Optional[str] = None


class StyleEngine:
    def __init__(
        self,
        api_key: str,
        model: str = "gpt-5-nano",
        reasoning_effort: Optional[str] = None,
        text_verbosity: Optional[str] = None,
        persona_gender_hint: Optional[str] = None,
    ) -> None:
        self._client = OpenAI(api_key=api_key)
        self._model = model
        self._reasoning_effort = reasoning_effort
        self._text_verbosity = text_verbosity
        self._persona_gender_hint = persona_gender_hint

    def generate_reply(
        self,
        username: str,
        display_name: str,
        samples: Iterable[StyleSample],
        starter: str,
        context: Optional[List[ContextMessage]] = None,
        peers: Optional[List[ParticipantProfile]] = None,
        requester: Optional[RequesterProfile] = None,
        persona_gender: Optional[str] = None,
        style_summary: Optional[str] = None,
        persona_card: Optional[str] = None,
        relationship_hint: Optional[str] = None,
    ) -> str:
        sample_block = "\n".join(f"- {sample.text}" for sample in samples)
        if not sample_block:
            raise ValueError("No samples supplied for style generation")

        summary_section = ""
        if style_summary:
            summary_section = f"Ð¥Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÑ‚Ð¸Ð»Ñ:\n{style_summary}\n\n"

        persona_section = ""
        if persona_card:
            persona_section = f"ÐšÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ° Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹:\n{persona_card}\n\n"

        relationship_section = ""
        if relationship_hint:
            relationship_section = (
                f"ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ð¹ Ñ Ð°Ð´Ñ€ÐµÑÐ°Ñ‚Ð¾Ð¼:\n{relationship_hint}\n\n"
            )

        context_section = ""
        if context:
            context_lines = "\n".join(
                f"{message.speaker}: {message.text}" for message in context
            )
            context_section = f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°:\n{context_lines}\n\n"

        peer_section = ""
        if peers:
            peer_lines: List[str] = []
            for profile in peers:
                if not profile.samples:
                    continue
                joined = " / ".join(profile.samples)
                peer_lines.append(f"{profile.name}: {joined}")
            if peer_lines:
                peer_section = "Ð”Ñ€ÑƒÐ³Ð¸Ðµ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¸ Ð¸ Ð¸Ñ… Ð¼Ð°Ð½ÐµÑ€Ð°:\n" + "\n".join(peer_lines) + "\n\n"

        requester_section = ""
        if requester:
            sample_hint = ""
            if requester.samples:
                joined = " / ".join(requester.samples)
                sample_hint = f" ÐžÐ½ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ Ð¿Ð¸ÑˆÐµÑ‚ Ñ‚Ð°Ðº: {joined}."
            requester_section = f"Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‘Ñ‚ {requester.name}.{sample_hint}\n"
            if requester.is_same_person:
                requester_section += REQUESTER_SELF_INSTRUCTION
            else:
                requester_section += REQUESTER_OTHER_INSTRUCTION
            requester_section += "\n\n"

        rules_section = IMITATION_RULES + "\n\n"

        prompt = (
            f"Ð¡Ð¾Ð±ÐµÑ€Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚ Ð² ÑÑ‚Ð¸Ð»Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {display_name}"
            f" (username: @{username}).\n\n"
            f"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ (Ð±ÐµÐ· Ð¸Ð¼ÐµÐ½):\n{sample_block}\n\n"
            f"{summary_section}"
            f"{persona_section}"
            f"{relationship_section}"
            f"{context_section}"
            f"{peer_section}"
            f"{requester_section}"
            f"{rules_section}"
            f"{self._gender_instruction(persona_gender)}"
            f"{starter.strip()}\n\n"
            "ÐžÑ‚Ð²ÐµÑ‚:"
        )

        kwargs: dict[str, object] = {}
        if self._reasoning_effort:
            kwargs["reasoning"] = {"effort": self._reasoning_effort}
        if self._text_verbosity:
            kwargs["text"] = {"verbosity": self._text_verbosity}

        response = self._client.responses.create(
            model=self._model,
            input=[
                {
                    "role": "system",
                    "content": IMITATION_SYSTEM,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
            **kwargs,
        )
        return response.output_text.strip()

    def _gender_instruction(self, persona_gender: Optional[str]) -> str:
        gender = persona_gender or self._persona_gender_hint
        if gender == "female":
            return GENDER_FEMALE_INSTRUCTION + "\n\n"
        if gender == "male":
            return GENDER_MALE_INSTRUCTION + "\n\n"
        return ""

    def generate_dialogue(
        self,
        participant_a: DialogueParticipant,
        participant_b: DialogueParticipant,
        topic: str,
    ) -> str:
        if not participant_a.samples or not participant_b.samples:
            raise ValueError("Both participants must have style samples for dialogue")

        topic_text = topic.strip() or "ÑÐ²Ð¾Ð±Ð¾Ð´Ð½ÑƒÑŽ Ñ‚ÐµÐ¼Ñƒ"

        def _participant_section(participant: DialogueParticipant) -> str:
            sample_block = "\n".join(f"- {sample.text}" for sample in participant.samples)
            summary = participant.style_summary or ""
            persona_card = participant.persona_card or ""
            relationship = participant.relationship_hint or ""
            parts: List[str] = [f"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ€ÐµÑ‡Ð¸:\n{sample_block}"]
            if summary:
                parts.append(f"Ð¡Ñ‚Ð¸Ð»ÑŒ: {summary}")
            if persona_card:
                parts.append(f"ÐŸÐµÑ€ÑÐ¾Ð½Ð°: {persona_card}")
            if relationship:
                parts.append(f"ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ: {relationship}")
            return "\n".join(parts)

        participant_sections = (
            f"{participant_a.name} (@{participant_a.username}):\n{_participant_section(participant_a)}\n\n"
            f"{participant_b.name} (@{participant_b.username}):\n{_participant_section(participant_b)}"
        )

        dialogue_rules = DIALOGUE_RULES_TEMPLATE.format(
            participant_a=participant_a.name,
            participant_b=participant_b.name,
        )
        prompt = (
            "Ð¡Ð¾ÑÑ‚Ð°Ð²ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹, ÑÐ²ÑÐ·Ð½Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð¼ÐµÐ¶Ð´Ñƒ Ð´Ð²ÑƒÐ¼Ñ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ°Ð¼Ð¸ Ñ‡Ð°Ñ‚Ð°."
            f" Ð¢ÐµÐ¼Ð° Ð±ÐµÑÐµÐ´Ñ‹: {topic_text}.\n\n"
            "Ð£Ñ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¸ Ð¸ Ð¸Ñ… ÑÑ‚Ð¸Ð»ÑŒ:\n"
            f"{participant_sections}\n\n"
            f"{dialogue_rules}"
        )

        response = self._client.responses.create(
            model=self._model,
            input=[
                {
                    "role": "system",
                    "content": IMITATION_SYSTEM,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
        )
        return response.output_text.strip()

    def generate_roast(
        self,
        username: str,
        display_name: str,
        samples: Iterable[StyleSample],
        style_summary: Optional[str] = None,
        persona_card: Optional[str] = None,
    ) -> str:
        """Generate a playful roast based on user's communication style."""
        sample_block = "\n".join(f"- {sample.text}" for sample in samples)
        if not sample_block:
            raise ValueError("No samples supplied for roast generation")

        summary_section = ""
        if style_summary:
            summary_section = f"\nÐ¥Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÑ‚Ð¸Ð»Ñ:\n{style_summary}\n"

        persona_section = ""
        if persona_card:
            persona_section = f"\nÐšÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ° Ð¿ÐµÑ€ÑÐ¾Ð½Ñ‹:\n{persona_card}\n"

        prompt = (
            f"Ð¡Ð´ÐµÐ»Ð°Ð¹ Ð´Ð¾Ð±Ñ€Ð¾Ð´ÑƒÑˆÐ½ÑƒÑŽ Â«Ð¿Ð¾Ð´Ð¶Ð°Ñ€ÐºÑƒÂ» Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ {display_name} (@{username}).\n\n"
            f"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ ÐµÐ³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹:\n{sample_block}\n"
            f"{summary_section}"
            f"{persona_section}\n"
            f"{ROAST_INSTRUCTIONS}"
        )

        kwargs: dict[str, object] = {}
        if self._reasoning_effort:
            kwargs["reasoning"] = {"effort": self._reasoning_effort}
        if self._text_verbosity:
            kwargs["text"] = {"verbosity": self._text_verbosity}

        response = self._client.responses.create(
            model=self._model,
            input=[
                {
                    "role": "system",
                    "content": ROAST_SYSTEM,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
            **kwargs,
        )
        return response.output_text.strip()

    def generate_compatibility(
        self,
        name_a: str,
        username_a: str,
        samples_a: Iterable[StyleSample],
        style_summary_a: Optional[str],
        name_b: str,
        username_b: str,
        samples_b: Iterable[StyleSample],
        style_summary_b: Optional[str],
    ) -> str:
        """Generate a fun compatibility analysis between two users."""
        sample_block_a = "\n".join(f"- {s.text}" for s in samples_a)
        sample_block_b = "\n".join(f"- {s.text}" for s in samples_b)

        if not sample_block_a or not sample_block_b:
            raise ValueError("Both users must have samples for compatibility check")

        summary_a = f"\nÐ¡Ñ‚Ð¸Ð»ÑŒ: {style_summary_a}" if style_summary_a else ""
        summary_b = f"\nÐ¡Ñ‚Ð¸Ð»ÑŒ: {style_summary_b}" if style_summary_b else ""

        instructions = COMPATIBILITY_INSTRUCTIONS.replace("{name_a}", name_a).replace("{name_b}", name_b)

        prompt = (
            f"Ð¡Ð¾ÑÑ‚Ð°Ð²ÑŒ ÑˆÑƒÑ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ Ñ‚ÐµÑÑ‚ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ {name_a} Ð¸ {name_b}.\n\n"
            f"ðŸ‘¤ {name_a} (@{username_a}):\n"
            f"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹:\n{sample_block_a}{summary_a}\n\n"
            f"ðŸ‘¤ {name_b} (@{username_b}):\n"
            f"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹:\n{sample_block_b}{summary_b}\n\n"
            f"{instructions}"
        )

        kwargs: dict[str, object] = {}
        if self._reasoning_effort:
            kwargs["reasoning"] = {"effort": self._reasoning_effort}
        if self._text_verbosity:
            kwargs["text"] = {"verbosity": self._text_verbosity}

        response = self._client.responses.create(
            model=self._model,
            input=[
                {
                    "role": "system",
                    "content": COMPATIBILITY_SYSTEM,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
            **kwargs,
        )
        return response.output_text.strip()

    def generate_story(
        self,
        characters: List[StoryCharacter],
        topic: Optional[str] = None,
        *,
        long_version: bool = False,
        reasoning_effort: Optional[str] = None,
    ) -> str:
        """
        Generate a short story with chat participants as characters.
        
        Args:
            characters: List of StoryCharacter with their speech samples
            topic: Optional story theme/setting
            long_version: If True, generate longer story (4000-6000 chars)
            reasoning_effort: Override reasoning effort for this call
        """
        if len(characters) < 2:
            raise ValueError("Story needs at least 2 characters")
        
        # Build character descriptions
        char_sections: List[str] = []
        for char in characters:
            sample_block = "\n".join(f"- {s.text}" for s in char.samples)
            if not sample_block:
                continue
            section = f"ðŸ‘¤ {char.name} (@{char.username}):\n"
            section += f"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ€ÐµÑ‡Ð¸:\n{sample_block}"
            if char.style_summary:
                section += f"\nÐ¥Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÑ‚Ð¸Ð»Ñ: {char.style_summary}"
            char_sections.append(section)
        
        if len(char_sections) < 2:
            raise ValueError("Not enough characters with samples for story")
        
        character_names = ", ".join(c.name for c in characters)
        topic_text = topic.strip() if topic else "Ð½Ð° ÑƒÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ½Ð¸Ðµ Ð°Ð²Ñ‚Ð¾Ñ€Ð°"
        
        instructions = STORY_LONG_INSTRUCTIONS if long_version else STORY_SHORT_INSTRUCTIONS
        
        prompt = (
            f"ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ñ€Ð°ÑÑÐºÐ°Ð· Ñ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð°Ð¼Ð¸: {character_names}.\n"
            f"Ð¢ÐµÐ¼Ð°/ÑÐµÑ‚Ñ‚Ð¸Ð½Ð³: {topic_text}.\n\n"
            "ÐŸÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð¸ Ð¸ Ð¸Ñ… ÑÑ‚Ð¸Ð»ÑŒ Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ:\n\n"
            + "\n\n".join(char_sections)
            + f"\n\n{instructions}"
        )
        
        kwargs: dict[str, object] = {}
        # Use provided reasoning_effort, fall back to instance default
        effort = reasoning_effort or self._reasoning_effort
        if effort:
            kwargs["reasoning"] = {"effort": effort}
        if self._text_verbosity:
            kwargs["text"] = {"verbosity": self._text_verbosity}
        
        response = self._client.responses.create(
            model=self._model,
            input=[
                {
                    "role": "system",
                    "content": STORY_SYSTEM,
                },
                {
                    "role": "user",
                    "content": prompt,
                },
            ],
            **kwargs,
        )
        return response.output_text.strip()
